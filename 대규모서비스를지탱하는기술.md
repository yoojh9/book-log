
# 웹 개발자를 위한 대규모 서비스를 지탱하는 기술

## 1. 대규모 데이터 처리의 어려운 점
#### 1-1. 메모리 내에서 계산할 수 없다
- 메모리에 올라가지 않으면 기본적으로 디스크를 계속 읽어가면서 검색하게 된다.
- 메모리 내에서 계산할 수 없게되면 디스크에 있는 데이터를 검색할 필요가 있다.
- 디스크는 메모리에 비해 상당히 느리다. 디스크는 느리므로 I/O(Input/Output)에 시간이 걸린다.
- 메모리는 디스크보다 탐색 속도 측면에서 10^5 ~ 10^6배 이상 빠르다

#### 1-2. 디스크는 왜 늦을까?
- 메모리는 전기적인 부품이므로 물리적 구조는 탐색 속도와 그다지 관계 없다.
- 디스크는 동축 상에 '원반'이 쌓여있다. 디스크는 메모리와는 달리 회전 등의 물리적인 동작을 수반한다. 이 물리적인 구조가 탐색 속도에 영향을 준다

#### 1-3. OS 레벨에서의 연구
- OS에서 느린 디스크를 어느정도 커버하기 위한 역할을 하는데, OS에서 연속된 데이터를 디스크의 같은 위치에 쌓는다
- 그 후 데이터를 읽을 때 1 바이트씩 읽는 것이 아니라 4KB(killobytes) 정도를 한꺼번에 읽도록 만들어 디스크의 회전횟수를 최소화 시킨다.

#### 1-4. 전송 속도, 버스의 속도 차
- 탐색 속도 측면에서 메모리가 디스크보다 빠르지만, 전송 속도 측면에서도 차이가 있다.
- 전송 속도는 찾은 데이터를 디스크에서 메모리로 보내거나 메모리에서 CPU로 보내는 등 컴퓨터 내부에서 전송하기 위한 속도이다.
- 메모리나 디스크 모두 CPU와 버스로 연결되어 있다. 이 버스 속도 역시 상당한 차이가 있다.
- SSD는 물리적인 회전이 아니므로 seek(탐색)에는 빠르지만 버스 속도가 병목이 되거나 그 밖에 구조에 기인하는 면이 있어 메모리만큼의 속도는 나오지 않는다.
<br>


## 2. 규모 조정의 요소
#### 2-1. 스케일업, 스케일아웃
- 스케일업(scale-up): 고가의 빠른 하드웨어를 사서 성능을 높이는 전략
- 스케일아웃(scale-out): 저가이면서 일반적인 성능의 하드웨어를 많이 나열에서 시스템 전체 성능을 올리는 전략 (주류)

#### 2-2. CPU 부하와 I/O 부하
- CPU 부하: HTTP 요청을 받아 DB에 질의하고 DB로부터 응답받은 데이터를 가공해서 HTML로 클라이언트에 반환할 때는 기본적으로 CPU 부하만 소요된다
- I/O부하: DB 서버 측면에서는 I/O 부하가 걸린다.

#### 2-3. 웹 어플리케이과 부하의 관계
- Application 서버
  - CPU 부하만 걸리므로 분산이 간단하다. 
  - 기본적으로 데이터를 분산해서 갖고 있는 것이 아니므로 동일한 호스트가 동일하게 작업을 처리하기만 하면 분산할 수 있다. 
  - 따라서 대수만 늘리기만 하면 간단히 확장할 수 있고, 새로운 서버를 추가한 후 요청을 균등하게 분산하기 위해 로드 밸런서(load balancer) 장치를 이용한다
  
- DB 서버
  - 만약 1번 서버에서 쓰기가 발생 하였다면 2번 서버는 어떻게 데이터를 동기화 할 것인가에 문제가 생긴다. 
  - 쓰기는 간단히 분산할 수 없다. 또한 어플리케이션 서버는 디스크를 거의 사용하지 않으므로 디스크에 관해서 신경쓰지 않아도 되지만, DB에서는 디스크를 많이 사용하므로 디스크 I/O를 많이 발생 시키는 구성으로 되어 있으면 속도차 문제가 생긴다. 
  - 게다가 데이터가 커질수록 메모리에서 처리하지 못하고 디스크상에서 처리할 수 밖에 없는 요건이 늘어난다.

#### 2-4. CPU 부하와 I/O 부하
- CPU 부하
  - 대규모의 과학 계산을 수행하는 프로그램이 있는데, '계산을 한다' 라는 것에서 생각할 수 있듯이, 이 프로그램의 처리 속도는 CPU의 계산 속도에 의존하고 있다.
   - 이것이 CPU에 부하를 주는 프로그램으로 'CPU 바운드한 프로그램'이라고 한다
  
- I/O 부하
  - 디스크에 저장된 대량의 데이터에서 임의의 문서를 찾아내는 검색 프로그램이 있다면, 이 검색 프로그램의 처리 속도는 CPU가 아닌 디스크의 읽기 속도, 즉 입출력에 의존할 것이다.
  - I/O에 부하를 주는 종류의 프로그램이라고 해서 'I/O 바운드한 프로그램'이라고 한다
 
- 일반적으로 Application 서버는 DB로부터 얻은 데이터를 가공해서 클라이언트로 전달하는 처리를 수행하므로, 대규모 I/O를 발생시키는 일은 드물다. 즉 AP 서버는 대부분 CPU 바운드한 서버라고 할 수 있다.
- 반면 DB서버는 데이터가 대규모가 될수록 CPU에서 계산 시간보다도 I/O에 대한 영향이 커지므로 I/O 바운드한 서버이다.
<br>


## 3. 대규모 데이터를 다루기 위한 지식
#### 3-1. 대규모 데이터를 다루기 위한 팁
- 어떻게 하면 메모리에서 처리를 마칠 수 있을까?
  - 디스크에서 seek 횟수 최소화
  - 국소성을 활용한 분산 실현
- 데이터량 증가에 강한 알고리즘, 데이터 구조
  - 선현검색 -> 이분검색
  - O(n) -> O(log n)
- 데이터 압축, 정보 검색 기술
  - 특정 용도에 특화된 검색엔진 등을 만들어, 해당 검색 시스템을 웹 어플리케이션에서 이용하는 형태로 전환

<br>
 
## 4. 메모리 단편화
- RAM에서 메모리의 공간이 작은 조각으로 나뉘어져 사용 가능한 메모리가 충분히 존재하지만 할당이 불가능한 상태를 메모리 단편화가 발생했다고 한다

#### 4-1. 내부 단편화
- 메모리를 할당할 때 프로세스가 필요한 양보다 더 큰 메모리가 할당되어서 프로세스에서 사용하는 메모리 공간이 낭비 되는 상황

#### 4-2. 외부 단편화
- 메모리가 할당되고 해제되는 작업이 반복될 때 작은 메모리가 중간중간 존재하게 되는데 이 때 중간중간에 사용하지 않는 메모리가 많이 존재해서 총 메모리 공간은 충분하지만 실제로 할당할 수 없는 상황

<br>

## 5. 가상 메모리 구조
- 가상 메모리 구조는 논리적인 선형 어드레스를 물리적인 물리 어드레스로 변환하는 것이다.
- OS는 메모리를 직접 프로세스로 넘기는 것이 아니라 일단 커널 내에서 메모리를 추상화 하고 있다.
- 가상 메모리는 32bit 시스템에 2GB 램으로 최대 4GB 할당 할 수 있게 해준다. 
- 주어진 RAM의 크기보다 초과되는 메모리 할당은 하드 디스크를 이용하며, 결국 32비트 시스템에서 프로세스에 할당할 수 있는 최대 크기인 4G바이트 메모리 공간은 RAM가 같은 메모리의 물리적 주소가 아니라 실제로 존재하지 않은 가상의 주소이다. 
- 그리고 가상의 주소를 사용하여 할당한 4G바이트에 해당하는 공간을 가상 메모리 공간(virtual adress space)이라고 한다
- 이런 가상 메모리 공간을 지정해 주기 위해 가상 주소 시스템이 필요하다

<br>

## 6. 메모리 단편화 해결 방법
#### 6-1. 페이징 기법 - 가상 메모리 사용, 외부 단편화 해결, 내부 단편화 존재
- 보조기억장치를 이용한 가상 메모리를 같은 크기의 블록으로 나눈 것을 페이지라고 하고 RAM을 페이지와 같은 크기로 나눈 것을 프레임이라고 한다.
- 페이징 기법이란 사용하지 않는 프레임을 페이지로 옮기고, 필요한 메모리를 페이지 단위로 프레임에 옮기는 기법이다
- 페이지와 프레임을 대응시키기 위해 page mapping 과정이 필요하므로 paging table을 만든다
- 페이징 기법을 사용하면 연속적이지 않은 공간도 활용할 수 있기 때문에 외부 단편화 문제를 해결할 수 있다.
- *외부단편화(External Fragmentation) : 빈 메모리 공간이 있지만 이 공간이 여러개의 불연속적인 작은 공간으로 나뉘어져 있어 프로세스를 할당 할 수 없는 상태. 외부 단편화는 심한 메모리 낭비의 원인이 된다.

- 하나의 프로세스가 연속된 메모리를 할당받을 필요 없이 여러 개의 페이지 조각으로 나뉘어져 분산 할당된다.
- 프로세스와 메모리가 동일한 크기로 규격화 됨으로써 외부 단편화가 발생하지 않는다.
- 대신 내부 단편화(Internal Fragmentation)가 발생하지만 심각한 수준은 아니다. 페이지 단위를 작게 하면 내부 단편화 문제도 해결할 수 있게지만 대신 page mapping 과정이 많아지므로 오히려 효율이 떨어질 수 있다.

#### 6-2. 세그멘테이션 기법 - 가상 메모리 사용, 내부 단편화 해결, 외부 단편화 존재
- 페이징 기법이 가상 메모리를 같은 크기의 단위로 분할 했다면 세그먼테이션 기법에서는 가상 메모리를 서로 다른 논리적 
단위의 크기인 세그먼트로 분할해서 메모리를 할당하여, 실제 메모리 주소로 변환 한다.
- 각 세그먼트는 연속적인 공간에 저장되어 있다. 세그먼트들의 크기가 다르므로 미리 분할할 수 없고 메모리가 적재될 때 빈 공간을 찾아 할당하는 기법이다.
- 페이징 기법과 마찬가지로 mapping을 위한 세그먼트 테이블이 필요하다. 각 세그먼트 항목 별로 세그먼트의 시작 주소와 세그먼트의 길이 정보를 가지고 있다
- 프로세스가 필요한 메모리만큼 할당해주기 때문에 내부 단편화는 발생하지 않으나 중간에 프로세스가 메모리를 해제하면 빈 메모리가 발생하게 되므로 외부 단편화 문제가 존재한다.

#### 6-3. 메모리 풀
- 필요한 메모리 공간을 필요한 크기, 개수 만큼 사용자가 직접 지정하여 미리 할당받아 놓고 필요할 때 마다 사용하고 반납하는 기법
- 미리 공간을 할당해놓고 가져다 쓰고 반납하기 때문에 할당과 해제로 인한 외부 단편화가 발생하지 않으며, 또한 필요한 크기만큼 할당해 놓기 때문에 내부 단편화도 발생하지 않는다.
- 메모리의 할당과 해제가 잦은 경우에는 메모리 풀을 쓰게 되면 효과적이다.

<br>

## 7. OS 캐시와 분산
#### 7-1. OS 캐시란
- OS에는 디스크 내의 데이터에 빠르게 액세스 할 수 있도록 하는 구조가 갖춰져 있다.
- OS는 메모리를 이용해서 디스크 액세스를 줄인다. 해당 방법을 알고 이를 통해 어플리케이션을 개발하게 되면 OS에 상당부분을 맡길 수 있다
- 이 원리가 바로 OS 캐시이다.

#### 7-2. Linux의 페이지 캐시 원리
- OS는 확보한 페이지를 메모리상에 계속 확보해두는 기능을 가지고 있다. 커널이 한번 할당한 메모리를 해제하지 않고 계속 남겨두는 것이 페이지 캐시이다.
- 리눅스는 한번 디스크에서 읽어낸 데이터는 가능한 한 메모리에 캐시를 해서 다음번 이후의 디스크 읽기(Disk Read)가 고속으로 수행되도록 조정한다.
- 리눅스는 가능한 한 남아있는 메모리를 페이지 캐시로 활용하려고 한다.
- 프로세스가 디스크로부터 데이터를 읽어내는 과정은 다음과 같다
  - 1) OS는 우선 디스크로부터 페이지 단위(4KB) 크기의 블록을 읽어낸다
  - 2) 프로세스는 디스크에 직접 액세스 할 수 없으므로 읽어낸 것은 메모리 상에 한번은 위치시켜야 한다. 프로세스가 액세스 할 수 있는 것은 (가상)메모리 이다.
  - 3) OS는 읽어낸 블록을 메모리에 쓴다.
  - 4) OS는 그 메모리 주소(가상 어드레스)를 프로세스에게 알려준다
  - 5) 프로세스는 가상 어드레스를 통해 해당 메모리에 액세스 한다.
  - 6) 프로세스1이 데이터 읽기를 다 마쳤더라도 메모리를 해제하지 않고 남겨두면 프로세스2가 같은 메모리 주소를 액세스 할 경우 남겨두었던 페이지를 다시 사용할 수 있다. 이것이 페이지 캐시이다.

#### 7-3. LRU(Least Recently Used)
- 캐시가 다 찼을 경우 최근에 읽은 부분이 캐시에 남고 과거에 읽은 부분이 파기된다.
- DB 역시 계속 구동 시키면 캐시가 점점 최적화 되어 가동시킨 직후보다 점점 뒤로 갈수록 부하, I/O가 내려가는 특성을 보인다.

#### 7-4. 페이지 캐시를 고려한 운용의 기본 규칙
- 1. OS 기동 직후에 서버를 투입하지 않는다. 갑자기 배치하면 캐시가 없으므로 오직 디스크 액세스만 발생한다. OS 시작하고 기동하면 자주 사용하는 DB 파일을 한번 cat 해준다. 그렇게 하면 전부 메모리에 올라간다.
- 2. 성능평가 시 캐시가 최적화된 후에 실시한다.

<br>

## 8. 국소성을 살리는 분산
#### 8-1. 국소성을 고려한 분산이란?
- 여러 대의 서버로 확장시키면 캐시 용량을 늘릴 수 있다.
- 만약 상품 리스트를 조회할 때 서버 A를 액세스하고, 장바구니 리스트를 조회할 때는 서버 B를 액세스 한다고 생각해보자.
- DB서버의 액세스 패턴에 따라 분산시킬 경우 캐싱할 수 없는 부분이 줄어들게 된다 (다양한 데이터를 캐싱 가능)
- 결국 시스템 전체로서는 메모리에 올라간 데이터 양이 늘어나게 된다.
- 메모리 증설이 어렵다면 분산을 고려하라.

#### 8-2. 국소성을 고려한 분산 1 - 파티셔닝
- 파티셔닝(partitioning)은 한 대였던 DB 서버를 여러 대의 서버로 분할하는 방법을 말한다.
- 분할 방법에는 여러가지가 있지만 가장 간단한 분할 방법은 '테이블 단위 분할'이다.
- 다른 분할 방법으로는 '테이블 데이터 분할'이 있다. 예를 들어 아이디의 첫글자가 a~d로 시작하면 서버 1, e~h인 사람은 서버 2와 같이 나눈다.

#### 8-3. 국소성을 고려한 분산 2 - 요청 패턴을 '섬'으로 분할
- 용도별로 시스템을 섬으로 나누는 방법도 있다.
- 책에서 나오는 하테나 북마크에서는 HTTP 요청의 User-Agent나 URL 등을 보고 일반 사용자라면 섬1, 일부 API 요청이면 섬2, Google bot이나 Yahoo 등의 봇이면 섬3와 같은 식으로 나누는 방법을 사용한다.
- 검색 봇은 특성상 아주 오래된 웹 페이지에도 액세스 하러 온다. 일반 사용자의 경우라면 좀처럼 액세스하지 않을 페이지에도 액세스 하고, 광범위하게 액세스 한다. 이런 현상으로 캐시가 작용하기 어렵다. 
- 봇에 대해서는 그렇게 빨리 응답할 필요가 없으므로 섬으로 남겨놓는다.
- 이렇게 되면 사용자로부터 빈번히 액세스가 일어나는 최상위 페이지나 인기 페이지는 빈번하게 참조되므로 캐싱하기 쉽다.
- 하지만 2010년 4월 구글이 웹 페이지의 응답속도를 검색랭킹 평가에 반영한다고 발표했으므로, 봇이라고 해도 응답 속도에 신경 써야 할 것으로 보인다.


---

참고 <br>

[BloBlog - \[OS\]가상메모리(VIrtual Memory)](https://mooneegee.blogspot.com/2015/01/osvirtual-memory-2-virtual-address.html) <br>
[운영체제, OS, Operating System](http://truemind5.blogspot.com/p/blog-page.html) <br>
[정아마추어 코딩블로그 - 메모리 단편화가 무엇이고 왜 발생하는가?](http://jeong-pro.tistory.com/91) <br>
